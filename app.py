# app.py

import streamlit as st
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns


# å¼•å…¥æˆ‘å€‘è‡ªå®šç¾©çš„æ¨¡çµ„
from data_utils import generate_and_prepare_data
from linear_regression import LinearRegression

plt.rcParams["font.family"] = "sans-serif"
plt.rcParams["axes.unicode_minus"] = False  # ç¢ºä¿è² è™Ÿå¯ä»¥æ­£å¸¸é¡¯ç¤º


# --- è¼”åŠ©å‡½æ•¸ (ç”¨æ–¼è¨ˆç®—è©•ä¼°æŒ‡æ¨™) ---
def mean_squared_error(y_true, y_pred):
    """è¨ˆç®—å‡æ–¹èª¤å·® (MSE)"""
    return np.mean((y_true - y_pred) ** 2)


def r2_score(y_true, y_pred):
    """è¨ˆç®— R-squared (R2 Score)"""
    corr_matrix = np.corrcoef(y_true.flatten(), y_pred.flatten())
    corr = corr_matrix[0, 1]
    return corr**2


# --- Streamlit æ‡‰ç”¨ç¨‹å¼ä»‹é¢ ---

st.set_page_config(layout="wide")

# 1. æ¨™é¡Œ
st.title("ğŸ“ˆ äº’å‹•å¼ç·šæ€§è¿´æ­¸è¦–è¦ºåŒ–å·¥å…·")
st.markdown(
    "é€™å€‹å·¥å…·è®“ä½ å¾é›¶é–‹å§‹æ¢ç´¢ç·šæ€§è¿´æ­¸ã€‚ä½ å¯ä»¥åœ¨å·¦å´çš„å´é‚Šæ¬„èª¿æ•´åƒæ•¸ï¼Œè§€å¯Ÿæ¨¡å‹çš„è®ŠåŒ–ã€‚"
)

# 2. å´é‚Šæ¬„ï¼šåƒæ•¸æ§åˆ¶
st.sidebar.header("âš™ï¸ åƒæ•¸è¨­å®š")

st.sidebar.subheader("ğŸ“Š æ•¸æ“šç”Ÿæˆåƒæ•¸")
n_samples = st.sidebar.slider("æ•¸æ“šé»æ•¸é‡ (N)", 50, 500, 100, 10)
slope = st.sidebar.slider("çœŸå¯¦æ–œç‡ (w)", -5.0, 5.0, 2.0, 0.1)
intercept = st.sidebar.slider("çœŸå¯¦æˆªè· (b)", -10.0, 10.0, 5.0, 0.5)
noise_level = st.sidebar.slider("é›œè¨Šç­‰ç´š", 0.0, 50.0, 20.0, 1.0)

st.sidebar.subheader("ğŸ§  æ¨¡å‹è¨“ç·´åƒæ•¸")
learning_rate = st.sidebar.select_slider(
    "å­¸ç¿’ç‡ (Learning Rate)", options=[0.0001, 0.001, 0.01, 0.1, 1.0], value=0.01
)
n_iterations = st.sidebar.slider("è¿­ä»£æ¬¡æ•¸", 100, 3000, 1000, 100)

# 3. æ•¸æ“šæº–å‚™èˆ‡æ¨¡å‹è¨“ç·´
# æ ¹æ“šå´é‚Šæ¬„çš„åƒæ•¸ç”Ÿæˆæ•¸æ“š
X_train, X_test, y_train, y_test, scaler = generate_and_prepare_data(
    n_samples=n_samples, slope=slope, intercept=intercept, noise_level=noise_level
)

# å»ºç«‹ä¸¦è¨“ç·´æ¨¡å‹
model = LinearRegression(learning_rate=learning_rate, n_iterations=n_iterations)
model.fit(X_train, y_train)

# é€²è¡Œé æ¸¬
y_pred_test = model.predict(X_test)

# 4. é¡¯ç¤ºçµæœ
st.header("âœ¨ çµæœèˆ‡åˆ†æ")

col1, col2 = st.columns((1, 1))

with col1:
    # æ­¥é©Ÿ 3: ç›£æ§æ”¶æ–‚éç¨‹
    st.subheader("ğŸ“‰ æˆæœ¬å‡½æ•¸æ”¶æ–‚éç¨‹")

    fig_cost, ax_cost = plt.subplots()
    ax_cost.plot(range(model.n_iterations), model.cost_history)
    ax_cost.set_xlabel("è¿­ä»£æ¬¡æ•¸ (Iterations)")
    ax_cost.set_ylabel("æˆæœ¬ (Cost - MSE)")
    ax_cost.set_title("Cost Function over Iterations")
    sns.despine(fig=fig_cost)
    st.pyplot(fig_cost)

    st.markdown("""
    ä¸Šåœ–é¡¯ç¤ºäº†éš¨è‘—è¨“ç·´çš„é€²è¡Œï¼Œæ¨¡å‹çš„æˆæœ¬ï¼ˆèª¤å·®ï¼‰å¦‚ä½•é€æ¼¸é™ä½ã€‚
    ä¸€å€‹ç†æƒ³çš„å­¸ç¿’ç‡æœƒè®“é€™æ¢æ›²ç·šå¹³æ»‘åœ°ä¸‹é™ä¸¦æ”¶æ–‚ã€‚
    - å¦‚æœæ›²ç·šä¸‹é™å¤ªæ…¢ï¼Œå¯ä»¥å˜—è©¦**æé«˜å­¸ç¿’ç‡**ã€‚
    - å¦‚æœæ›²ç·šåŠ‡çƒˆéœ‡ç›ªæˆ–ç™¼æ•£ï¼Œè¡¨ç¤ºå­¸ç¿’ç‡å¤ªé«˜ï¼Œéœ€è¦**é™ä½å­¸ç¿’ç‡**ã€‚
    """)

with col2:
    # æ­¥é©Ÿ 4: è©•ä¼°èˆ‡è¦–è¦ºåŒ–é æ¸¬
    st.subheader("ğŸ¯ é æ¸¬çµæœè¦–è¦ºåŒ–")

    fig_pred, ax_pred = plt.subplots()
    # åŸå§‹æ•¸æ“šé» (æ¸¬è©¦é›†)
    ax_pred.scatter(
        scaler.inverse_transform(X_test),
        y_test,
        alpha=0.7,
        label="çœŸå¯¦å€¼ (Actual Values)",
    )
    # è¿´æ­¸ç·š
    ax_pred.plot(
        scaler.inverse_transform(X_test),
        y_pred_test,
        color="red",
        linewidth=2,
        label="é æ¸¬ç·š (Prediction)",
    )
    ax_pred.set_xlabel("ç‰¹å¾µ (Feature X)")
    ax_pred.set_ylabel("ç›®æ¨™ (Target y)")
    ax_pred.set_title("Prediction vs. Actual Values")
    ax_pred.legend()
    sns.despine(fig=fig_pred)
    st.pyplot(fig_pred)

    st.markdown("""
    ä¸Šåœ–å±•ç¤ºäº†æ¨¡å‹åœ¨**æœªè¦‹éçš„æ¸¬è©¦æ•¸æ“š**ä¸Šçš„è¡¨ç¾ã€‚
    - **è—é»**æ˜¯çœŸå¯¦çš„æ•¸æ“šåˆ†ä½ˆã€‚
    - **ç´…ç·š**æ˜¯æˆ‘å€‘çš„æ¨¡å‹å­¸ç¿’åˆ°çš„ç·šæ€§é—œä¿‚ã€‚
    ç´…ç·šè¶Šèƒ½è²¼è¿‘è—é»çš„åˆ†ä½ˆè¶¨å‹¢ï¼Œä»£è¡¨æ¨¡å‹å­¸å¾—è¶Šå¥½ã€‚
    """)

# æ­¥é©Ÿ 4: è¨ˆç®—è©•ä¼°æŒ‡æ¨™
st.subheader("ğŸ“ æ¨¡å‹è©•ä¼°æŒ‡æ¨™")
mse = mean_squared_error(y_test, y_pred_test)
r2 = r2_score(y_test, y_pred_test)

metric1, metric2, metric3, metric4 = st.columns(4)
metric1.metric(label="å‡æ–¹èª¤å·® (MSE)", value=f"{mse:.2f}")
metric2.metric(label="R-squared (RÂ² Score)", value=f"{r2:.4f}")

st.info(
    f"æ¨¡å‹å­¸ç¿’åˆ°çš„æ¬Šé‡ (w): **{model.weights[0][0]:.4f}** | å­¸ç¿’åˆ°çš„åç½® (b): **{model.bias:.4f}**",
    icon="ğŸ§ ",
)


st.header("ğŸ“œ çµè«–")
st.markdown("""
é€™å€‹äº’å‹•å·¥å…·å±•ç¤ºäº†ç·šæ€§è¿´æ­¸çš„æ ¸å¿ƒæµç¨‹ã€‚é€éèª¿æ•´å·¦å´çš„åƒæ•¸ï¼Œæˆ‘å€‘å¯ä»¥è§€å¯Ÿåˆ°ï¼š
1.  **æ•¸æ“šç‰¹æ€§**ï¼šå¢åŠ  `é›œè¨Šç­‰ç´š` æœƒè®“æ•¸æ“šé»æ›´åˆ†æ•£ï¼Œæ¨¡å‹æ›´é›£æ‰¾åˆ°æœ€ä½³æ“¬åˆç·šï¼Œå°è‡´ RÂ² åˆ†æ•¸ä¸‹é™ã€‚
2.  **æ¨¡å‹è¨“ç·´**ï¼š`å­¸ç¿’ç‡` å’Œ `è¿­ä»£æ¬¡æ•¸` ç›´æ¥å½±éŸ¿æ¨¡å‹çš„æ”¶æ–‚æ•ˆæœã€‚ä¸æ°ç•¶çš„å­¸ç¿’ç‡æœƒå°è‡´æˆæœ¬ç„¡æ³•æœ‰æ•ˆé™ä½ã€‚
3.  **å¾é›¶å¯¦ä½œ**ï¼šæˆ‘å€‘åº•å±¤ä½¿ç”¨çš„ `LinearRegression` é¡åˆ¥æ˜¯å®Œå…¨å¾é›¶æ‰“é€ çš„ï¼ŒæˆåŠŸå¯¦ç¾äº†æ¢¯åº¦ä¸‹é™çš„å„ªåŒ–éç¨‹ã€‚

æˆ‘å€‘å·²ç¶“æˆåŠŸå®Œæˆäº† `Todo.md` ä¸­å®šç¾©çš„æ‰€æœ‰ä¸»è¦æ­¥é©Ÿï¼
""")
